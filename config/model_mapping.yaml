version: '2.0'
default:
  model: gpt-4o-mini
  temperature: 0
  max_tokens: 4000
  timeout_seconds: 120
  provider: openai
routing:
  phase:
    analyst:
      model: gpt-4o
      temperature: 0.1
      max_tokens: 8000
      provider: openai
    architect:
      model: gpt-4o
      temperature: 0.1
      max_tokens: 16000
      provider: openai
    implementation:
      model: gpt-4o
      temperature: 0
      max_tokens: 8000
      provider: openai
    testing:
      model: gpt-4o-mini
      temperature: 0
      max_tokens: 4000
      provider: openai
  specialty:
    backend:
      model: gpt-4o
      temperature: 0
      max_tokens: 8000
      provider: openai
      efcore:
        model: gpt-4o
        temperature: 0
        max_tokens: 8000
        provider: openai
    frontend:
      model: gpt-4o-mini
      temperature: 0
      max_tokens: 6000
      provider: openai
      react:
        model: gpt-4o-mini
        temperature: 0
        max_tokens: 6000
        provider: openai
    review:
      model: gpt-4o
      temperature: 0.1
      max_tokens: 8000
      provider: openai
    documentation:
      model: gemini-2.5-pro
      temperature: 0.2
      max_tokens: 32000
      provider: google
