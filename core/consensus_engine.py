"""\nConsensus engine for multi-model decision making.\n\nThis module implements consensus mechanisms where critical decisions\nare made by multiple LLM models voting or providing proposals that\nare synthesized into a final decision.\n\nTypical use cases:\n- Architecture design (Claude Sonnet + GPT-4o + Gemini 2.5 Pro)\n- Critical design decisions requiring multiple perspectives\n- High-stakes code review\n\nVersion: 2.0.0\n\"""\n\nfrom __future__ import annotations\n\nimport asyncio\nimport logging\nimport json\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass\nfrom collections import Counter\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Proposal:\n    \"\"\"A single proposal from one model.\"\"\"\n    model: str\n    provider: str\n    content: str\n    metadata: Dict[str, Any]\n    tokens_used: Dict[str, int]\n    confidence: float = 0.0\n\n\n@dataclass\nclass ConsensusResult:\n    \"\"\"Result of consensus decision making.\"\"\"\n    final_decision: str\n    proposals: List[Proposal]\n    synthesis_reasoning: str\n    agreement_level: float  # 0.0-1.0\n    total_tokens: int\n    total_cost: float\n    method: str  # \"majority_vote\" or \"weighted_synthesis\"\n\n\nclass ConsensusEngine:\n    \"\"\"\n    Orchestrate multi-model consensus for critical decisions.\n    \n    The engine supports two consensus methods:\n    1. **Majority vote**: Each model produces a structured decision,\n       and the most common choice is selected.\n    2. **Weighted synthesis**: A high-capability model (Claude Sonnet)\n       reviews all proposals and synthesizes a final decision.\n    \n    Example\n    -------\n    >>> from core.llm_client_v2 import LLMClient\n    >>> from core.model_router_v2 import ModelRouter\n    >>> from core.cost_manager import CostManager\n    >>> \n    >>> cost_mgr = CostManager()\n    >>> llm_client = LLMClient(cost_mgr)\n    >>> router = ModelRouter()\n    >>> engine = ConsensusEngine(llm_client, router, cost_mgr)\n    >>> \n    >>> consensus_config = router.get_consensus_models(\"architect\")\n    >>> result = await engine.reach_consensus(\n    ...     prompt=\"Design a scalable REST API architecture for...\",\n    ...     consensus_config=consensus_config,\n    ...     method=\"weighted_synthesis\"\n    ... )\n    >>> print(result.final_decision)\n    >>> print(f\"Agreement: {result.agreement_level:.1%}\")\n    \"\"\"\n    \n    def __init__(self, llm_client: Any, router: Any, cost_manager: Any):\n        self.llm_client = llm_client\n        self.router = router\n        self.cost_manager = cost_manager\n    \n    async def reach_consensus(\n        self,\n        prompt: str,\n        consensus_config: Any,  # ConsensusConfig from model_router_v2\n        method: str = \"weighted_synthesis\",\n        context: Optional[str] = None\n    ) -> ConsensusResult:\n        \"\"\"\n        Execute consensus process with multiple models.\n        \n        Parameters\n        ----------\n        prompt : str\n            The question or task for consensus.\n        consensus_config : ConsensusConfig\n            Configuration containing primary, secondary, tertiary models.\n        method : str\n            \"majority_vote\" or \"weighted_synthesis\" (default).\n        context : str, optional\n            Additional context to provide to all models.\n        \n        Returns\n        -------\n        ConsensusResult\n            Final decision with all proposals and metadata.\n        \"\"\"\n        logger.info(f\"Starting consensus with method: {method}\")\n        \n        # Build messages\n        messages = []\n        if context:\n            messages.append({\n                \"role\": \"system\",\n                \"content\": f\"Context:\\n{context}\"\n            })\n        messages.append({\n            \"role\": \"user\",\n            \"content\": prompt\n        })\n        \n        # Gather proposals from all models in parallel\n        proposals = await self._gather_proposals(messages, consensus_config)\n        \n        # Calculate total cost\n        total_tokens = sum(p.tokens_used[\"total\"] for p in proposals)\n        total_cost = self.cost_manager.get_cumulative_cost()\n        \n        # Execute consensus method\n        if method == \"majority_vote\":\n            decision, agreement, reasoning = await self._majority_vote(proposals)\n        else:  # weighted_synthesis\n            decision, agreement, reasoning = await self._weighted_synthesis(\n                proposals, consensus_config, messages\n            )\n        \n        return ConsensusResult(\n            final_decision=decision,\n            proposals=proposals,\n            synthesis_reasoning=reasoning,\n            agreement_level=agreement,\n            total_tokens=total_tokens,\n            total_cost=total_cost,\n            method=method\n        )\n    \n    async def _gather_proposals(\n        self,\n        messages: List[Dict[str, str]],\n        consensus_config: Any\n    ) -> List[Proposal]:\n        \"\"\"Gather proposals from all consensus models in parallel.\"\"\"\n        tasks = []\n        \n        # Primary model\n        tasks.append(self._get_proposal(\n            messages,\n            consensus_config.primary.model,\n            consensus_config.primary.provider,\n            consensus_config.weight_primary\n        ))\n        \n        # Secondary model\n        tasks.append(self._get_proposal(\n            messages,\n            consensus_config.secondary.model,\n            consensus_config.secondary.provider,\n            consensus_config.weight_secondary\n        ))\n        \n        # Tertiary model (optional)\n        if consensus_config.tertiary:\n            tasks.append(self._get_proposal(\n                messages,\n                consensus_config.tertiary.model,\n                consensus_config.tertiary.provider,\n                consensus_config.weight_tertiary\n            ))\n        \n        # Execute in parallel\n        proposals = await asyncio.gather(*tasks)\n        return [p for p in proposals if p is not None]\n    \n    async def _get_proposal(\n        self,\n        messages: List[Dict[str, str]],\n        model: str,\n        provider: str,\n        weight: float\n    ) -> Optional[Proposal]:\n        \"\"\"Get a single proposal from one model.\"\"\"\n        try:\n            response = await self.llm_client.complete(\n                messages=messages,\n                model=model,\n                temperature=0.1,  # Slight randomness for diversity\n                max_tokens=8000\n            )\n            \n            return Proposal(\n                model=model,\n                provider=provider,\n                content=response.content,\n                metadata=response.metadata,\n                tokens_used=response.tokens_used,\n                confidence=weight  # Use weight as initial confidence\n            )\n        except Exception as e:\n            logger.error(f\"Failed to get proposal from {model}: {e}\")\n            return None\n    \n    async def _majority_vote(\n        self,\n        proposals: List[Proposal]\n    ) -> tuple[str, float, str]:\n        \"\"\"\n        Simple majority voting for structured decisions.\n        \n        Expects each proposal to contain JSON with a \"decision\" key.\n        Returns the most common decision.\n        \"\"\"\n        decisions = []\n        \n        for proposal in proposals:\n            try:\n                # Try to extract JSON decision\n                content = proposal.content.strip()\n                if content.startswith(\"```json\"):\n                    content = content.split(\"```json\")[1].split(\"```\")[0]\n                \n                data = json.loads(content)\n                decision = data.get(\"decision\", content)\n                decisions.append(decision)\n            except json.JSONDecodeError:\n                # Fall back to raw content\n                decisions.append(proposal.content[:200])  # First 200 chars\n        \n        # Count votes\n        vote_counts = Counter(decisions)\n        most_common = vote_counts.most_common(1)[0]\n        winning_decision = most_common[0]\n        votes = most_common[1]\n        \n        agreement = votes / len(proposals) if proposals else 0.0\n        \n        reasoning = (\n            f\"Majority vote: {votes}/{len(proposals)} models agreed. \"\n            f\"Vote distribution: {dict(vote_counts)}\"\n        )\n        \n        return winning_decision, agreement, reasoning\n    \n    async def _weighted_synthesis(\n        self,\n        proposals: List[Proposal],\n        consensus_config: Any,\n        original_messages: List[Dict[str, str]]\n    ) -> tuple[str, float, str]:\n        \"\"\"\n        Synthesize proposals using a high-capability model.\n        \n        Claude Sonnet reviews all proposals and creates a final decision\n        that incorporates the best ideas from each.\n        \"\"\"\n        # Build synthesis prompt\n        proposals_text = \"\\n\\n\".join([\n            f\"## Proposal {i+1} ({p.model}):\\n{p.content}\"\n            for i, p in enumerate(proposals)\n        ])\n        \n        synthesis_prompt = f\"\"\"You are tasked with synthesizing multiple architectural proposals into a single, coherent decision.\n\nOriginal question:\n{original_messages[-1]['content']}\n\n---\n\n{proposals_text}\n\n---\n\nPlease:\n1. Identify common themes and agreements across proposals.\n2. Resolve any contradictions by choosing the most robust approach.\n3. Produce a final, comprehensive decision that incorporates the best ideas from all proposals.\n4. Rate the overall agreement level (0.0-1.0) based on how aligned the proposals were.\n\nRespond in JSON format:\n{{\n  \"final_decision\": \"...\",\n  \"reasoning\": \"...\",\n  \"agreement_level\": 0.85\n}}\n\"\"\"\n        \n        # Use synthesis model (typically Claude Sonnet)\n        synthesis_response = await self.llm_client.complete(\n            messages=[{\"role\": \"user\", \"content\": synthesis_prompt}],\n            model=consensus_config.synthesis_model,\n            temperature=0.0,\n            max_tokens=8000\n        )\n        \n        # Parse synthesis result\n        try:\n            content = synthesis_response.content.strip()\n            if content.startswith(\"```json\"):\n                content = content.split(\"```json\")[1].split(\"```\")[0]\n            \n            synthesis_data = json.loads(content)\n            final_decision = synthesis_data[\"final_decision\"]\n            reasoning = synthesis_data[\"reasoning\"]\n            agreement = synthesis_data.get(\"agreement_level\", 0.8)\n        except (json.JSONDecodeError, KeyError) as e:\n            logger.error(f\"Failed to parse synthesis result: {e}\")\n            # Fall back to raw content\n            final_decision = synthesis_response.content\n            reasoning = \"Synthesis completed (raw format)\"\n            agreement = 0.7\n        \n        return final_decision, agreement, reasoning\n
